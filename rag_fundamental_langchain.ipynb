{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772f2cf4",
   "metadata": {},
   "source": [
    "# ğŸ¦œğŸ”— RAG Fundamentals with LangChain & Groq\n",
    "\n",
    "Welcome to **RAG (Retrieval Augmented Generation) Fundamentals**! This notebook teaches you how to build a RAG pipeline using LangChain and the **free Groq API**.\n",
    "\n",
    "## What is RAG?\n",
    "RAG combines **retrieval** (finding relevant documents) with **generation** (LLM response). Instead of relying only on the LLM's training data, we provide context from our own documents.\n",
    "\n",
    "```\n",
    "User Query â†’ Retrieve Relevant Docs â†’ Augment Prompt with Context â†’ Generate Answer\n",
    "```\n",
    "\n",
    "## What You'll Learn:\n",
    "1. **Document Loaders** - Load PDFs and other documents\n",
    "2. **Text Splitters** - Chunk documents for processing\n",
    "3. **Embeddings** - Convert text to vectors\n",
    "4. **Vector Stores** - Store and search embeddings\n",
    "5. **Retrievers** - Find relevant documents\n",
    "6. **RAG Chains** - Build end-to-end question answering\n",
    "\n",
    "## Dataset\n",
    "We'll use **Landmark Judgments of the Supreme Court of India** PDF to build a legal Q&A system.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- Complete the LangChain Fundamentals notebook first\n",
    "- Groq API key in your `.env` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa6b84b",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation\n",
    "\n",
    "Install the required packages for RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24bb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# %pip install langchain langchain-groq langchain-huggingface langchain-community -q\n",
    "# %pip install pypdf faiss-cpu sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"âš ï¸ GROQ_API_KEY not found! Set it in your .env file or uncomment below:\")\n",
    "    # os.environ[\"GROQ_API_KEY\"] = \"your-groq-api-key-here\"\n",
    "else:\n",
    "    print(\"âœ… GROQ_API_KEY loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9617c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e11d3c1",
   "metadata": {},
   "source": [
    "## 2. Document Loaders\n",
    "\n",
    "**Document Loaders** load data from various sources (PDFs, web pages, databases) into a standard `Document` format.\n",
    "\n",
    "Each `Document` has:\n",
    "- `page_content`: The text content\n",
    "- `metadata`: Information about the source (page number, file name, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc665f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "131897a3",
   "metadata": {},
   "source": [
    "## 3. Text Splitters\n",
    "\n",
    "LLMs have **context length limits**. We need to split documents into smaller **chunks** that:\n",
    "- Fit within the model's context window\n",
    "- Contain semantically meaningful content\n",
    "- Have some overlap to maintain context between chunks\n",
    "\n",
    "### Key Parameters:\n",
    "- `chunk_size`: Maximum characters per chunk\n",
    "- `chunk_overlap`: Characters shared between consecutive chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378fa90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0d489fc",
   "metadata": {},
   "source": [
    "## 4. Embeddings\n",
    "\n",
    "**Embeddings** convert text into numerical vectors that capture semantic meaning. Similar texts have similar vectors.\n",
    "\n",
    "```\n",
    "\"The court ruled in favor\" â†’ [0.23, -0.45, 0.67, ...]\n",
    "\"The judgment was positive\" â†’ [0.21, -0.43, 0.65, ...]  â† Similar vector!\n",
    "```\n",
    "\n",
    "We'll use **HuggingFace embeddings** (free, runs locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754f228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f8bae31",
   "metadata": {},
   "source": [
    "## 5. Vector Stores\n",
    "\n",
    "**Vector Stores** are databases optimized for storing and searching embeddings. They enable fast **similarity search**.\n",
    "\n",
    "Popular options:\n",
    "- **FAISS** (Facebook AI) - Fast, in-memory, free\n",
    "- **Chroma** - Easy to use, persistent storage\n",
    "- **Pinecone** - Cloud-based, scalable\n",
    "\n",
    "We'll use **FAISS** (free and fast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e0b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b9438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7598b25c",
   "metadata": {},
   "source": [
    "## 6. Retrievers\n",
    "\n",
    "A **Retriever** is an interface that returns relevant documents given a query. Vector stores can be converted to retrievers.\n",
    "\n",
    "### Retriever Types:\n",
    "- **Similarity** - Returns top k most similar documents\n",
    "- **MMR (Maximum Marginal Relevance)** - Balances relevance with diversity\n",
    "- **Self-Query** - LLM generates filter queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846f8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07bcc60c",
   "metadata": {},
   "source": [
    "## 7. RAG Chain - Putting It All Together\n",
    "\n",
    "Now we combine everything into a **RAG Chain**:\n",
    "\n",
    "```\n",
    "Query â†’ Retriever â†’ Relevant Docs â†’ Prompt + Context â†’ LLM â†’ Answer\n",
    "```\n",
    "\n",
    "We'll create a prompt that instructs the LLM to answer based ONLY on the provided context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced943f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e3323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f97511fa",
   "metadata": {},
   "source": [
    "## 8. Test the RAG System\n",
    "\n",
    "Let's ask questions about Indian Supreme Court landmark judgments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700e2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5cd7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fd934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f34da8a",
   "metadata": {},
   "source": [
    "## 9. RAG with Source Attribution\n",
    "\n",
    "Good RAG systems show **which documents** were used to generate the answer. Let's create a version that returns sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b1f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc19de7",
   "metadata": {},
   "source": [
    "## 10. Streaming RAG Responses\n",
    "\n",
    "For better user experience, stream the response token by token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0617a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "353e171c",
   "metadata": {},
   "source": [
    "## 11. Save & Load Vector Store\n",
    "\n",
    "Save the vector store to disk so you don't have to re-embed documents each time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5f573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7553c470",
   "metadata": {},
   "source": [
    "## 12. Interactive Q&A Function\n",
    "\n",
    "Create a reusable function for asking questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87a6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8da3eb4f",
   "metadata": {},
   "source": [
    "## ğŸ¯ Summary\n",
    "\n",
    "In this notebook, you learned the **RAG Fundamentals**:\n",
    "\n",
    "| Component | What You Learned |\n",
    "|-----------|------------------|\n",
    "| **Document Loaders** | Load PDFs with `PyPDFLoader` |\n",
    "| **Text Splitters** | Chunk documents with `RecursiveCharacterTextSplitter` |\n",
    "| **Embeddings** | Convert text to vectors with `HuggingFaceEmbeddings` |\n",
    "| **Vector Stores** | Store and search with `FAISS` |\n",
    "| **Retrievers** | Find relevant documents with similarity search |\n",
    "| **RAG Chains** | Combine retrieval + generation with LCEL |\n",
    "| **Source Attribution** | Return sources alongside answers |\n",
    "| **Streaming** | Stream responses for better UX |\n",
    "| **Persistence** | Save/load vector stores |\n",
    "\n",
    "---\n",
    "\n",
    "### RAG Pipeline Architecture:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  PDF/Docs   â”‚â”€â”€â”€â–¶â”‚   Chunks    â”‚â”€â”€â”€â–¶â”‚  Embeddings â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                            â”‚\n",
    "                                            â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Answer    â”‚â—€â”€â”€â”€â”‚     LLM     â”‚â—€â”€â”€â”€â”‚ Vector Storeâ”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          â–²                  â”‚\n",
    "                          â”‚                  â–¼\n",
    "                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                   â”‚   Prompt    â”‚â—€â”€â”€â”€â”‚  Retriever  â”‚â—€â”€â”€ Query\n",
    "                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "- Add more document types (web pages, APIs)\n",
    "- Experiment with different chunk sizes\n",
    "- Try different embedding models\n",
    "- Add conversation memory for multi-turn chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-basic-test-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
