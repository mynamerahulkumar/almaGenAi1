{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "772f2cf4",
      "metadata": {
        "id": "772f2cf4"
      },
      "source": [
        "# ğŸ¦œğŸ”— RAG Fundamentals with LangChain & Groq\n",
        "\n",
        "Welcome to **RAG (Retrieval Augmented Generation) Fundamentals**! This notebook teaches you how to build a RAG pipeline using LangChain and the **free Groq API**.\n",
        "\n",
        "## What is RAG?\n",
        "RAG combines **retrieval** (finding relevant documents) with **generation** (LLM response). Instead of relying only on the LLM's training data, we provide context from our own documents.\n",
        "\n",
        "```\n",
        "User Query â†’ Retrieve Relevant Docs â†’ Augment Prompt with Context â†’ Generate Answer\n",
        "```\n",
        "\n",
        "## What You'll Learn:\n",
        "1. **Document Loaders** - Load PDFs and other documents\n",
        "2. **Text Splitters** - Chunk documents for processing\n",
        "3. **Embeddings** - Convert text to vectors\n",
        "4. **Vector Stores** - Store and search embeddings\n",
        "5. **Retrievers** - Find relevant documents\n",
        "6. **RAG Chains** - Build end-to-end question answering\n",
        "\n",
        "## Dataset\n",
        "We'll use **Landmark Judgments of the Supreme Court of India** PDF to build a legal Q&A system.\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "- Complete the LangChain Fundamentals notebook first\n",
        "- Groq API key in your `.env` file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa6b84b",
      "metadata": {
        "id": "4aa6b84b"
      },
      "source": [
        "## 1. Setup & Installation\n",
        "\n",
        "Install the required packages for RAG:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a24bb6e5",
      "metadata": {
        "id": "a24bb6e5"
      },
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# %pip install langchain langchain-groq langchain-huggingface langchain-community -q\n",
        "# %pip install pypdf faiss-cpu sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8280800f",
      "metadata": {
        "id": "8280800f",
        "outputId": "1309805f-330a-47c8-9595-d7116a35ec9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… GROQ_API_KEY loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Verify API key\n",
        "api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "if not api_key:\n",
        "    print(\"âš ï¸ GROQ_API_KEY not found! Set it in your .env file or uncomment below:\")\n",
        "    # os.environ[\"GROQ_API_KEY\"] = \"your-groq-api-key-here\"\n",
        "else:\n",
        "    print(\"âœ… GROQ_API_KEY loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d9617c5c",
      "metadata": {
        "id": "d9617c5c",
        "outputId": "89ced85e-f5a5-41b3-828f-a9a529b64462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… LLM initialized: llama-3.3-70b-versatile\n"
          ]
        }
      ],
      "source": [
        "# Initialize Groq LLM\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0,  # Lower temperature for factual responses\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "print(f\"âœ… LLM initialized: {llm.model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e11d3c1",
      "metadata": {
        "id": "4e11d3c1"
      },
      "source": [
        "## 2. Document Loaders\n",
        "\n",
        "**Document Loaders** load data from various sources (PDFs, web pages, databases) into a standard `Document` format.\n",
        "\n",
        "Each `Document` has:\n",
        "- `page_content`: The text content\n",
        "- `metadata`: Information about the source (page number, file name, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fcc665f5",
      "metadata": {
        "id": "fcc665f5",
        "outputId": "86e70cd3-575e-4b71-b261-fde08d0c0e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“„ Loaded 13 pages from the PDF\n",
            "\n",
            "--- First Page Preview ---\n",
            "Content (first 500 chars): AMAZON.COM ANNOUNCES THIRD QUARTER RESULTS\n",
            "SEATTLEâ€”(BUSINESS WIRE) October 30, 2025â€”Amazon.com, Inc. (NASDAQ: AMZN) today announced financial \n",
            "results for its third quarter ended September 30, 2025. \n",
            "â€¢ Net sales increased 13% to $180.2 billion in the third quarter, compared with $158.9 billion in third quarter 2024.\n",
            "Excluding the $1.5 billion favorable impact from year-over-year changes in foreign exchange rates throughout the\n",
            "quarter, net sales increased 12% compared with third quarter 2024.\n",
            "â€¢ ...\n",
            "\n",
            "Metadata: {'producer': 'Wdesk Fidelity Content Translations Version 014.006.087', 'creator': 'Workiva', 'creationdate': '2025-10-30T16:57:42+00:00', 'author': 'anonymous', 'moddate': '2025-10-30T09:59:42-07:00', 'title': 'AMZN-2025.09.30-EX99.1', 'source': 'data/AMZN-Q3-2025-Earnings-Release.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load the Supreme Court Landmark Judgments PDF\n",
        "pdf_path = \"data/AMZN-Q3-2025-Earnings-Release.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "\n",
        "# Load all pages as documents\n",
        "documents = loader.load()\n",
        "\n",
        "print(f\"ğŸ“„ Loaded {len(documents)} pages from the PDF\")\n",
        "print(f\"\\n--- First Page Preview ---\")\n",
        "print(f\"Content (first 500 chars): {documents[0].page_content[:500]}...\")\n",
        "print(f\"\\nMetadata: {documents[0].metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "131897a3",
      "metadata": {
        "id": "131897a3"
      },
      "source": [
        "## 3. Text Splitters\n",
        "\n",
        "LLMs have **context length limits**. We need to split documents into smaller **chunks** that:\n",
        "- Fit within the model's context window\n",
        "- Contain semantically meaningful content\n",
        "- Have some overlap to maintain context between chunks\n",
        "\n",
        "### Key Parameters:\n",
        "- `chunk_size`: Maximum characters per chunk\n",
        "- `chunk_overlap`: Characters shared between consecutive chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2378fa90",
      "metadata": {
        "id": "2378fa90",
        "outputId": "1d28d72f-b725-425b-e262-6813548a91c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¦ Split 13 pages into 46 chunks\n",
            "\n",
            "--- Sample Chunk ---\n",
            "Chunk 5 content: Some other highlights since the companyâ€™s last earnings announcement include that Amazon:\n",
            "â€¢ Saw continued strong adoption of Trainium2, its custom AI chip, which is fully subscribed and a multi-billion-dollar \n",
            "business that grew 150% quarter over quarter. \n",
            "â€¢ Launched Project Rainier, a massive AI co...\n",
            "Chunk 5 metadata: {'producer': 'Wdesk Fidelity Content Translations Version 014.006.087', 'creator': 'Workiva', 'creationdate': '2025-10-30T16:57:42+00:00', 'author': 'anonymous', 'moddate': '2025-10-30T09:59:42-07:00', 'title': 'AMZN-2025.09.30-EX99.1', 'source': 'data/AMZN-Q3-2025-Earnings-Release.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Create a text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,      # Max characters per chunk\n",
        "    chunk_overlap=200,    # Overlap between chunks for context\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Split priorities\n",
        ")\n",
        "\n",
        "# Split documents into chunks\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"ğŸ“¦ Split {len(documents)} pages into {len(chunks)} chunks\")\n",
        "print(f\"\\n--- Sample Chunk ---\")\n",
        "print(f\"Chunk 5 content: {chunks[5].page_content[:300]}...\")\n",
        "print(f\"Chunk 5 metadata: {chunks[5].metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0d489fc",
      "metadata": {
        "id": "d0d489fc"
      },
      "source": [
        "## 4. Embeddings\n",
        "\n",
        "**Embeddings** convert text into numerical vectors that capture semantic meaning. Similar texts have similar vectors.\n",
        "\n",
        "```\n",
        "\"The court ruled in favor\" â†’ [0.23, -0.45, 0.67, ...]\n",
        "\"The judgment was positive\" â†’ [0.21, -0.43, 0.65, ...]  â† Similar vector!\n",
        "```\n",
        "\n",
        "We'll use **HuggingFace embeddings** (free, runs locally)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3754f228",
      "metadata": {
        "id": "3754f228",
        "outputId": "0b8c8eeb-c68c-482c-f6db-edeea02558eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Embeddings model loaded: all-MiniLM-L6-v2\n",
            "ğŸ“ Embedding dimension: 384\n",
            "ğŸ”¢ First 5 values: [-0.05370708182454109, 0.05493843927979469, -0.07679767161607742, -0.050161395221948624, -0.06389239430427551]\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize embeddings model (free, runs locally)\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # Fast and efficient\n",
        "    model_kwargs={'device': 'cpu'},  # Use 'cuda' if you have GPU\n",
        ")\n",
        "\n",
        "# Test the embeddings\n",
        "sample_text = \"The Supreme Court of India\"\n",
        "embedding_vector = embeddings.embed_query(sample_text)\n",
        "\n",
        "print(f\"âœ… Embeddings model loaded: all-MiniLM-L6-v2\")\n",
        "print(f\"ğŸ“ Embedding dimension: {len(embedding_vector)}\")\n",
        "print(f\"ğŸ”¢ First 5 values: {embedding_vector[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f8bae31",
      "metadata": {
        "id": "9f8bae31"
      },
      "source": [
        "## 5. Vector Stores\n",
        "\n",
        "**Vector Stores** are databases optimized for storing and searching embeddings. They enable fast **similarity search**.\n",
        "\n",
        "Popular options:\n",
        "- **FAISS** (Facebook AI) - Fast, in-memory, free\n",
        "- **Chroma** - Easy to use, persistent storage\n",
        "- **Pinecone** - Cloud-based, scalable\n",
        "\n",
        "We'll use **FAISS** (free and fast)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7b6e0b2a",
      "metadata": {
        "id": "7b6e0b2a",
        "outputId": "ef1baad2-4b3b-4209-af0f-bd40485bdfcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Vector store created with 46 vectors\n",
            "ğŸ“Š Index type: FAISS (in-memory)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Create vector store from document chunks\n",
        "# This embeds all chunks and stores them in FAISS\n",
        "vectorstore = FAISS.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "print(f\"âœ… Vector store created with {len(chunks)} vectors\")\n",
        "print(f\"ğŸ“Š Index type: FAISS (in-memory)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ee5b9438",
      "metadata": {
        "id": "ee5b9438",
        "outputId": "2afa5860-36d2-4e76-90ee-f4a43f1349a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Query: 'What is the Amazon AI Revenue'\n",
            "\n",
            "ğŸ“„ Top 3 similar documents:\n",
            "\n",
            "--- Document 1 (Page 0) ---\n",
            "â€¢ Operating cash flow increased 16% to $130.7 billion for the trailing twelve months, compared with $112.7 billion for\n",
            "the trailing twelve months ended September 30, 2024.\n",
            "â€¢ Free cash flow decreased to $14.8 billion for the trailing twelve months, driven primarily by a year-over-year increase\n",
            "of $50...\n",
            "\n",
            "--- Document 2 (Page 7) ---\n",
            "AMAZON.COM, INC.\n",
            "Segment Information\n",
            "(in millions)\n",
            "(unaudited) \n",
            "  \n",
            "Three Months Ended\n",
            "September 30,\n",
            "Nine Months Ended\n",
            "September 30,\n",
            "2024 2025 2024 2025\n",
            "North America\n",
            "Net sales $ 95,537 $ 106,267 $ 271,911 $ 299,222 \n",
            "Operating expenses  89,874  101,478  256,200  281,075 \n",
            "Operating income $ 5,663 $ 4,...\n",
            "\n",
            "--- Document 3 (Page 5) ---\n",
            "AMAZON.COM, INC.\n",
            "Consolidated Statements of Operations\n",
            "(in millions, except per share data)\n",
            "(unaudited)\n",
            "  \n",
            "Three Months Ended\n",
            "September 30,\n",
            "Nine Months Ended\n",
            "September 30,\n",
            "2024 2025 2024 2025\n",
            "Net product sales $ 67,601 $ 74,058 $ 190,085 $ 206,274 \n",
            "Net service sales  91,276  106,111  260,082  297,26...\n"
          ]
        }
      ],
      "source": [
        "# Test similarity search\n",
        "query = \"What is the Amazon AI Revenue\"\n",
        "similar_docs = vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "print(f\"ğŸ” Query: '{query}'\")\n",
        "print(f\"\\nğŸ“„ Top 3 similar documents:\")\n",
        "for i, doc in enumerate(similar_docs, 1):\n",
        "    print(f\"\\n--- Document {i} (Page {doc.metadata.get('page', 'N/A')}) ---\")\n",
        "    print(doc.page_content[:300] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7598b25c",
      "metadata": {
        "id": "7598b25c"
      },
      "source": [
        "## 6. Retrievers\n",
        "\n",
        "A **Retriever** is an interface that returns relevant documents given a query. Vector stores can be converted to retrievers.\n",
        "\n",
        "### Retriever Types:\n",
        "- **Similarity** - Returns top k most similar documents\n",
        "- **MMR (Maximum Marginal Relevance)** - Balances relevance with diversity\n",
        "- **Self-Query** - LLM generates filter queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9846f8f5",
      "metadata": {
        "id": "9846f8f5",
        "outputId": "2ecad36b-2733-4a53-b5f7-6adf89895d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Query: 'What are AWS AI Investement plan?'\n",
            "ğŸ“„ Retrieved 4 documents\n",
            "\n",
            "--- Doc 1 ---\n",
            "â€¢ Operating cash flow increased 16% to $130.7 billion for the trailing twelve months, compared with $112.7 billion for\n",
            "the trailing twelve months ended September 30, 2024.\n",
            "â€¢ Free cash flow decreased t...\n",
            "\n",
            "--- Doc 2 ---\n",
            "employees interact with AI agents that can find insights, conduct research, and take actions across systems. Quick \n",
            "Suite helps turn month-long projects into days, get 80%+ time savings on complex tas...\n",
            "\n",
            "--- Doc 3 ---\n",
            "Qwen3, as well as Anthropicâ€™s Claude Sonnet 4.5, Claude Opus 4.1, and Claude Haiku 4.5.\n",
            "â€¢ Announced a number of new Amazon EC2 instances for general purpose computing, including AWS Graviton4 chips \n",
            "f...\n",
            "\n",
            "--- Doc 4 ---\n",
            "Some other highlights since the companyâ€™s last earnings announcement include that Amazon:\n",
            "â€¢ Saw continued strong adoption of Trainium2, its custom AI chip, which is fully subscribed and a multi-billio...\n"
          ]
        }
      ],
      "source": [
        "# Convert vector store to retriever\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",  # or \"mmr\" for diversity\n",
        "    search_kwargs={\"k\": 4}     # Return top 4 documents\n",
        ")\n",
        "\n",
        "# Test retriever\n",
        "query = \"What are AWS AI Investement plan?\"\n",
        "retrieved_docs = retriever.invoke(query)\n",
        "\n",
        "print(f\"ğŸ” Query: '{query}'\")\n",
        "print(f\"ğŸ“„ Retrieved {len(retrieved_docs)} documents\")\n",
        "for i, doc in enumerate(retrieved_docs, 1):\n",
        "    print(f\"\\n--- Doc {i} ---\")\n",
        "    print(doc.page_content[:200] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07bcc60c",
      "metadata": {
        "id": "07bcc60c"
      },
      "source": [
        "## 7. RAG Chain - Putting It All Together\n",
        "\n",
        "Now we combine everything into a **RAG Chain**:\n",
        "\n",
        "```\n",
        "Query â†’ Retriever â†’ Relevant Docs â†’ Prompt + Context â†’ LLM â†’ Answer\n",
        "```\n",
        "\n",
        "We'll create a prompt that instructs the LLM to answer based ONLY on the provided context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9ced943f",
      "metadata": {
        "id": "9ced943f",
        "outputId": "01f7f222-55ca-4303-a0fc-a662581515b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RAG prompt template created\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Create RAG prompt template\n",
        "rag_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a helpful financial assistant specializing in Stock Market investment.\n",
        "Answer the question based ONLY on the following context from  Amazon Q3 2025 Eearning Results.\n",
        "If the answer is not found in the context, say \"I cannot find this information in the provided documents.\"\n",
        "\n",
        "Context:\n",
        "{context}\"\"\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "print(\"âœ… RAG prompt template created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f86e3323",
      "metadata": {
        "id": "f86e3323",
        "outputId": "ae31dd77-7408-452d-b425-c961689db619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RAG chain created!\n"
          ]
        }
      ],
      "source": [
        "# Helper function to format retrieved documents\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Build the RAG chain using LCEL\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever | format_docs,  # Retrieve and format docs\n",
        "        \"question\": RunnablePassthrough()     # Pass through the question\n",
        "    }\n",
        "    | rag_prompt     # Create the prompt\n",
        "    | llm            # Generate response\n",
        "    | StrOutputParser()  # Parse to string\n",
        ")\n",
        "\n",
        "print(\"âœ… RAG chain created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f97511fa",
      "metadata": {
        "id": "f97511fa"
      },
      "source": [
        "## 8. Test the RAG System\n",
        "\n",
        "Let's ask questions about Indian Supreme Court landmark judgments!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a700e2b2",
      "metadata": {
        "id": "a700e2b2",
        "outputId": "11ef13cb-201d-42fa-b82e-cf546fbce5ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ Question: What is the AWS Revenue?\n",
            "\n",
            "==================================================\n",
            "\n",
            "ğŸ’¡ Answer:\n",
            "The AWS revenue for the three months ended September 30, 2025, is $33,006 million, and for the nine months ended September 30, 2025, it is $93,146 million.\n"
          ]
        }
      ],
      "source": [
        "# Question 1: Kesavananda Bharati Case\n",
        "question = \"What is the AWS Revenue?\"\n",
        "\n",
        "print(f\"â“ Question: {question}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "answer = rag_chain.invoke(question)\n",
        "print(f\"\\nğŸ’¡ Answer:\\n{answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5cd7ab",
      "metadata": {
        "id": "8a5cd7ab",
        "outputId": "09e574cd-a6c7-41a9-c5dd-048295e35e0b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f5fd934",
      "metadata": {
        "id": "3f5fd934",
        "outputId": "78a41e52-f8b7-4d40-d7d1-612a479d38ae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6f34da8a",
      "metadata": {
        "id": "6f34da8a"
      },
      "source": [
        "## 9. RAG with Source Attribution\n",
        "\n",
        "Good RAG systems show **which documents** were used to generate the answer. Let's create a version that returns sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "233b1f9c",
      "metadata": {
        "id": "233b1f9c",
        "outputId": "cc64eacc-d645-4a2f-b2cf-93103141ef07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ Question: What is AWS Revenue?\n",
            "\n",
            "==================================================\n",
            "\n",
            "ğŸ’¡ Answer:\n",
            "According to the provided context, AWS revenue for the:\n",
            "\n",
            "- Three Months Ended September 30, 2024: $27,452 million\n",
            "- Three Months Ended September 30, 2025: $33,006 million\n",
            "- Nine Months Ended September 30, 2024: $78,770 million\n",
            "- Nine Months Ended September 30, 2025: $93,146 million\n",
            "\n",
            "==================================================\n",
            "\n",
            "ğŸ“š Sources used:\n",
            "  1. Page 7: AMAZON.COM, INC.\n",
            "Segment Information\n",
            "(in millions)\n",
            "(unaudited) \n",
            "  \n",
            "Three Months Ended\n",
            "September 30,\n",
            "...\n",
            "  2. Page 0: â€¢ Operating cash flow increased 16% to $130.7 billion for the trailing twelve months, compared with ...\n",
            "  3. Page 5: AMAZON.COM, INC.\n",
            "Consolidated Statements of Operations\n",
            "(in millions, except per share data)\n",
            "(unaudit...\n",
            "  4. Page 7: Operating income  17,411  17,422  47,390  54,998 \n",
            "Total non-operating income (expense)  626  10,748 ...\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# Create a chain that returns both answer and source documents\n",
        "rag_chain_with_sources = RunnableParallel(\n",
        "    {\n",
        "        \"answer\": rag_chain,\n",
        "        \"sources\": retriever\n",
        "    }\n",
        ")\n",
        "\n",
        "# Test with sources\n",
        "question = \"What is AWS Revenue?\"\n",
        "result = rag_chain_with_sources.invoke(question)\n",
        "\n",
        "print(f\"â“ Question: {question}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"\\nğŸ’¡ Answer:\\n{result['answer']}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"\\nğŸ“š Sources used:\")\n",
        "for i, doc in enumerate(result['sources'], 1):\n",
        "    page = doc.metadata.get('page', 'N/A')\n",
        "    print(f\"  {i}. Page {page}: {doc.page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dc19de7",
      "metadata": {
        "id": "2dc19de7"
      },
      "source": [
        "## 10. Streaming RAG Responses\n",
        "\n",
        "For better user experience, stream the response token by token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3d0617a4",
      "metadata": {
        "id": "3d0617a4",
        "outputId": "624a6003-f811-4e90-d01b-808eaaa94d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ Question: What is AWS  Trainium2?\n",
            "\n",
            "ğŸ’¡ Streaming Answer:\n",
            "----------------------------------------\n",
            "According to the context, Trainium2 is Amazon's custom AI chip. It is a multi-billion-dollar business that grew 150% quarter over quarter and is fully subscribed. Additionally, nearly 500,000 Trainium2 chips are being used in Project Rainier, a massive AI compute cluster, to build and deploy Anthropic's leading Claude AI models.\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Stream the response\n",
        "question = \"What is AWS  Trainium2?\"\n",
        "\n",
        "print(f\"â“ Question: {question}\")\n",
        "print(\"\\nğŸ’¡ Streaming Answer:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for chunk in rag_chain.stream(question):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "353e171c",
      "metadata": {
        "id": "353e171c"
      },
      "source": [
        "## 11. Save & Load Vector Store\n",
        "\n",
        "Save the vector store to disk so you don't have to re-embed documents each time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a1b5f573",
      "metadata": {
        "id": "a1b5f573",
        "outputId": "d7e9b5bf-9328-4bba-fe18-3f21b3a35993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Vector store saved to 'faiss_supreme_court_index'\n"
          ]
        }
      ],
      "source": [
        "# Save vector store to disk\n",
        "vectorstore.save_local(\"faiss_supreme_court_index\")\n",
        "print(\"âœ… Vector store saved to 'faiss_supreme_court_index'\")\n",
        "\n",
        "# Load it back (useful for future sessions)\n",
        "# loaded_vectorstore = FAISS.load_local(\n",
        "#     \"faiss_supreme_court_index\",\n",
        "#     embeddings,\n",
        "#     allow_dangerous_deserialization=True\n",
        "# )\n",
        "# print(\"âœ… Vector store loaded from disk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7553c470",
      "metadata": {
        "id": "7553c470"
      },
      "source": [
        "## 12. Interactive Q&A Function\n",
        "\n",
        "Create a reusable function for asking questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5d87a6a1",
      "metadata": {
        "id": "5d87a6a1",
        "outputId": "f4ccb46c-b38b-46fc-cda0-335219555898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ Question: What is AWS Revenue?\n",
            "============================================================\n",
            "\n",
            "ğŸ’¡ Answer:\n",
            "According to the provided context, AWS revenue for the:\n",
            "\n",
            "- Three Months Ended September 30, 2024: $27,452 million\n",
            "- Three Months Ended September 30, 2025: $33,006 million\n",
            "- Nine Months Ended September 30, 2024: $78,770 million\n",
            "- Nine Months Ended September 30, 2025: $93,146 million\n",
            "\n",
            "============================================================\n",
            "\n",
            "ğŸ“š Sources:\n",
            "  [1] Page 7\n",
            "  [2] Page 0\n",
            "  [3] Page 5\n",
            "  [4] Page 7\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "def ask_financial_question(question: str, show_sources: bool = True):\n",
        "    \"\"\"\n",
        "    Ask a question about Indian Supreme Court landmark judgments.\n",
        "\n",
        "    Args:\n",
        "        question: Your legal question\n",
        "        show_sources: Whether to show source documents\n",
        "    \"\"\"\n",
        "    print(f\"â“ Question: {question}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if show_sources:\n",
        "        result = rag_chain_with_sources.invoke(question)\n",
        "        print(f\"\\nğŸ’¡ Answer:\\n{result['answer']}\")\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"\\nğŸ“š Sources:\")\n",
        "        for i, doc in enumerate(result['sources'], 1):\n",
        "            page = doc.metadata.get('page', 'N/A')\n",
        "            print(f\"  [{i}] Page {page}\")\n",
        "    else:\n",
        "        answer = rag_chain.invoke(question)\n",
        "        print(f\"\\nğŸ’¡ Answer:\\n{answer}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Example usage\n",
        "ask_financial_question(\"What is AWS Revenue?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da3eb4f",
      "metadata": {
        "id": "8da3eb4f"
      },
      "source": [
        "## ğŸ¯ Summary\n",
        "\n",
        "In this notebook, you learned the **RAG Fundamentals**:\n",
        "\n",
        "| Component | What You Learned |\n",
        "|-----------|------------------|\n",
        "| **Document Loaders** | Load PDFs with `PyPDFLoader` |\n",
        "| **Text Splitters** | Chunk documents with `RecursiveCharacterTextSplitter` |\n",
        "| **Embeddings** | Convert text to vectors with `HuggingFaceEmbeddings` |\n",
        "| **Vector Stores** | Store and search with `FAISS` |\n",
        "| **Retrievers** | Find relevant documents with similarity search |\n",
        "| **RAG Chains** | Combine retrieval + generation with LCEL |\n",
        "| **Source Attribution** | Return sources alongside answers |\n",
        "| **Streaming** | Stream responses for better UX |\n",
        "| **Persistence** | Save/load vector stores |\n",
        "\n",
        "---\n",
        "\n",
        "### RAG Pipeline Architecture:\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  PDF/Docs   â”‚â”€â”€â”€â–¶â”‚   Chunks    â”‚â”€â”€â”€â–¶â”‚  Embeddings â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                            â”‚\n",
        "                                            â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚   Answer    â”‚â—€â”€â”€â”€â”‚     LLM     â”‚â—€â”€â”€â”€â”‚ Vector Storeâ”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                          â–²                  â”‚\n",
        "                          â”‚                  â–¼\n",
        "                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                   â”‚   Prompt    â”‚â—€â”€â”€â”€â”‚  Retriever  â”‚â—€â”€â”€ Query\n",
        "                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Next Steps:\n",
        "- Add more document types (web pages, APIs)\n",
        "- Experiment with different chunk sizes\n",
        "- Try different embedding models\n",
        "- Add conversation memory for multi-turn chat"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "almagenai1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
